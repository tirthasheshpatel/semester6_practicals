{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Prac6.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "27SYmLbTFMfm"
      },
      "source": [
        "# Prac 6\r\n",
        "### 18BCE259\r\n",
        "\r\n",
        "##### Processing Text with RNN"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jKjn_mrzFLQX",
        "outputId": "17e6975f-7745-4427-dbe3-93fb7608489c"
      },
      "source": [
        "!nvidia-smi"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mon Mar  8 08:50:09 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 460.32.03    CUDA Version: 11.2     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla K80           Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   67C    P8    31W / 149W |      0MiB / 11441MiB |      0%      Default |\n",
            "|                               |                      |                  N/A |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vyf7ErOnFJeT"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import tensorflow.keras as keras\r\n",
        "import numpy as np\r\n",
        "import matplotlib.pyplot as plt"
      ],
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vrZRsxXvAkb0"
      },
      "source": [
        "import logging\r\n",
        "logging.getLogger(\"tensorflow\").setLevel(logging.ERROR)\r\n",
        "logging.getLogger(\"tensorflow\").addHandler(logging.NullHandler(logging.ERROR))"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2fUi--a86lQd"
      },
      "source": [
        "data = \" It is well known that medical diagnosis takes more time than deciding treatment for the condition .\\n It might require plenty of time and skills of medical practitioners .\\n In recent times, COVID-19 spread across the globe made computer researchers work toward faster and more accurate medical diagnosis solutions for hospitals .\\n This project contains the code for diagnosing pneumonia from the chest X-ray images .\"\r\n",
        "text = data.split('\\n')"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "n6LcTLeYHSCr"
      },
      "source": [
        "tokenizer = tf.keras.preprocessing.text.Tokenizer(filters='!\"#$*&()*+,-/:;<=>?@[\\]^_{}~')\r\n",
        "tokenizer.fit_on_texts(text)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5FdyJMkKH2Ng",
        "outputId": "f3e8d186-82a2-48be-9b96-fe7b3d9f081e"
      },
      "source": [
        "vocab_size = len(tokenizer.word_index) + 1\r\n",
        "vocab_size"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "53"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6jf3BFbJIEUY"
      },
      "source": [
        "sequences = tokenizer.texts_to_sequences(text)\r\n",
        "l = len(sequences)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mpOwRqchInaR",
        "outputId": "9684dc03-0439-400e-f08c-677210996d57"
      },
      "source": [
        "max_len = max([len(seq) for seq in sequences])\r\n",
        "max_len"
      ],
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "24"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 8
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6y5kl9sbLg1v"
      },
      "source": [
        "X = []\r\n",
        "y = sequences\r\n",
        "for sq in sequences:\r\n",
        "    X.append(sq[:-1])"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x3heNcPE-HtW"
      },
      "source": [
        "max_len = max([len(seq) for seq in sequences])"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7aqT1o4m8EiH"
      },
      "source": [
        "X = tf.keras.preprocessing.sequence.pad_sequences(X, maxlen=max_len+1)\r\n",
        "y = tf.keras.preprocessing.sequence.pad_sequences(y, maxlen=max_len+1)\r\n",
        "y = tf.keras.utils.to_categorical(y, num_classes=vocab_size)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jEj_xWea8x6u",
        "outputId": "602ee189-698b-40d2-9a3c-5617b221303e"
      },
      "source": [
        "model = tf.keras.models.Sequential([\r\n",
        "                                    tf.keras.layers.Embedding(input_dim=vocab_size, output_dim=10),\r\n",
        "                                    tf.keras.layers.SimpleRNN(50, return_sequences=True),\r\n",
        "                                    tf.keras.layers.Dense(vocab_size, activation=\"softmax\")\r\n",
        "])\r\n",
        "\r\n",
        "model.summary()"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "embedding (Embedding)        (None, None, 10)          530       \n",
            "_________________________________________________________________\n",
            "simple_rnn (SimpleRNN)       (None, None, 50)          3050      \n",
            "_________________________________________________________________\n",
            "dense (Dense)                (None, None, 53)          2703      \n",
            "=================================================================\n",
            "Total params: 6,283\n",
            "Trainable params: 6,283\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4gCKUCx39dqV",
        "outputId": "0e2bdf3a-3a78-49e2-dbc6-380a5f308f60"
      },
      "source": [
        "model.compile(optimizer=\"RMSprop\", loss=\"categorical_crossentropy\", metrics=['accuracy'])\r\n",
        "model.fit(X,y, epochs=200)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/200\n",
            "1/1 [==============================] - 1s 1s/step - loss: 3.9763 - accuracy: 0.0100\n",
            "Epoch 2/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.9193 - accuracy: 0.0400\n",
            "Epoch 3/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.8636 - accuracy: 0.0400\n",
            "Epoch 4/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.8258 - accuracy: 0.0500\n",
            "Epoch 5/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.7934 - accuracy: 0.1700\n",
            "Epoch 6/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.7614 - accuracy: 0.3300\n",
            "Epoch 7/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.7308 - accuracy: 0.3100\n",
            "Epoch 8/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.6944 - accuracy: 0.3300\n",
            "Epoch 9/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.6608 - accuracy: 0.3500\n",
            "Epoch 10/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 3.6176 - accuracy: 0.3600\n",
            "Epoch 11/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.5812 - accuracy: 0.3600\n",
            "Epoch 12/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 3.5406 - accuracy: 0.3600\n",
            "Epoch 13/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.5229 - accuracy: 0.3600\n",
            "Epoch 14/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.4715 - accuracy: 0.3600\n",
            "Epoch 15/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.4261 - accuracy: 0.3600\n",
            "Epoch 16/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 3.3885 - accuracy: 0.3600\n",
            "Epoch 17/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3650 - accuracy: 0.3600\n",
            "Epoch 18/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.3450 - accuracy: 0.3600\n",
            "Epoch 19/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.3285 - accuracy: 0.3600\n",
            "Epoch 20/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.2724 - accuracy: 0.3600\n",
            "Epoch 21/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.2366 - accuracy: 0.3600\n",
            "Epoch 22/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 3.2191 - accuracy: 0.3600\n",
            "Epoch 23/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.2049 - accuracy: 0.3500\n",
            "Epoch 24/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.1670 - accuracy: 0.3600\n",
            "Epoch 25/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.1331 - accuracy: 0.3500\n",
            "Epoch 26/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 3.1006 - accuracy: 0.3600\n",
            "Epoch 27/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.0932 - accuracy: 0.3600\n",
            "Epoch 28/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 3.1058 - accuracy: 0.3600\n",
            "Epoch 29/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 3.0768 - accuracy: 0.3600\n",
            "Epoch 30/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 3.0115 - accuracy: 0.3500\n",
            "Epoch 31/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.9856 - accuracy: 0.3500\n",
            "Epoch 32/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.9616 - accuracy: 0.3500\n",
            "Epoch 33/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.9385 - accuracy: 0.3600\n",
            "Epoch 34/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.9181 - accuracy: 0.3500\n",
            "Epoch 35/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.9105 - accuracy: 0.3600\n",
            "Epoch 36/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.9381 - accuracy: 0.3700\n",
            "Epoch 37/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.9296 - accuracy: 0.3800\n",
            "Epoch 38/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.8686 - accuracy: 0.3700\n",
            "Epoch 39/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.8737 - accuracy: 0.3600\n",
            "Epoch 40/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.8376 - accuracy: 0.3800\n",
            "Epoch 41/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.8277 - accuracy: 0.3600\n",
            "Epoch 42/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.7813 - accuracy: 0.3700\n",
            "Epoch 43/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7602 - accuracy: 0.3800\n",
            "Epoch 44/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7418 - accuracy: 0.3700\n",
            "Epoch 45/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.7268 - accuracy: 0.3800\n",
            "Epoch 46/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.7199 - accuracy: 0.4000\n",
            "Epoch 47/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7513 - accuracy: 0.3700\n",
            "Epoch 48/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.7364 - accuracy: 0.3800\n",
            "Epoch 49/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.7588 - accuracy: 0.3700\n",
            "Epoch 50/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.6873 - accuracy: 0.3700\n",
            "Epoch 51/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6630 - accuracy: 0.3600\n",
            "Epoch 52/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.6571 - accuracy: 0.3700\n",
            "Epoch 53/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6179 - accuracy: 0.3800\n",
            "Epoch 54/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.6038 - accuracy: 0.4100\n",
            "Epoch 55/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.5976 - accuracy: 0.3800\n",
            "Epoch 56/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.6107 - accuracy: 0.4300\n",
            "Epoch 57/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.6740 - accuracy: 0.3700\n",
            "Epoch 58/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.5607 - accuracy: 0.4000\n",
            "Epoch 59/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.5491 - accuracy: 0.3800\n",
            "Epoch 60/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.5418 - accuracy: 0.4000\n",
            "Epoch 61/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.5360 - accuracy: 0.3900\n",
            "Epoch 62/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.5331 - accuracy: 0.4000\n",
            "Epoch 63/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.5345 - accuracy: 0.3900\n",
            "Epoch 64/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.5187 - accuracy: 0.4400\n",
            "Epoch 65/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.5368 - accuracy: 0.3800\n",
            "Epoch 66/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.4773 - accuracy: 0.4400\n",
            "Epoch 67/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.4686 - accuracy: 0.3800\n",
            "Epoch 68/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.4465 - accuracy: 0.4400\n",
            "Epoch 69/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 2.4386 - accuracy: 0.3800\n",
            "Epoch 70/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.4257 - accuracy: 0.4400\n",
            "Epoch 71/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 2.4251 - accuracy: 0.3900\n",
            "Epoch 72/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.4162 - accuracy: 0.4400\n",
            "Epoch 73/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4278 - accuracy: 0.3900\n",
            "Epoch 74/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.4070 - accuracy: 0.4400\n",
            "Epoch 75/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.4121 - accuracy: 0.4000\n",
            "Epoch 76/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.3871 - accuracy: 0.4000\n",
            "Epoch 77/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.3695 - accuracy: 0.4100\n",
            "Epoch 78/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 2.3523 - accuracy: 0.4000\n",
            "Epoch 79/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.3333 - accuracy: 0.4100\n",
            "Epoch 80/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.3226 - accuracy: 0.4500\n",
            "Epoch 81/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.3332 - accuracy: 0.3900\n",
            "Epoch 82/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.3726 - accuracy: 0.4300\n",
            "Epoch 83/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 2.4181 - accuracy: 0.3900\n",
            "Epoch 84/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.3085 - accuracy: 0.3900\n",
            "Epoch 85/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2842 - accuracy: 0.4100\n",
            "Epoch 86/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2667 - accuracy: 0.4100\n",
            "Epoch 87/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.2528 - accuracy: 0.4200\n",
            "Epoch 88/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.2408 - accuracy: 0.4400\n",
            "Epoch 89/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.2301 - accuracy: 0.4500\n",
            "Epoch 90/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.2206 - accuracy: 0.4500\n",
            "Epoch 91/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.2138 - accuracy: 0.4500\n",
            "Epoch 92/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.2145 - accuracy: 0.4600\n",
            "Epoch 93/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.2384 - accuracy: 0.4000\n",
            "Epoch 94/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.2662 - accuracy: 0.4400\n",
            "Epoch 95/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.2934 - accuracy: 0.4100\n",
            "Epoch 96/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.1971 - accuracy: 0.4400\n",
            "Epoch 97/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.1791 - accuracy: 0.4200\n",
            "Epoch 98/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 2.1591 - accuracy: 0.4500\n",
            "Epoch 99/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.1485 - accuracy: 0.4400\n",
            "Epoch 100/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 2.1377 - accuracy: 0.4500\n",
            "Epoch 101/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.1318 - accuracy: 0.4500\n",
            "Epoch 102/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 2.1263 - accuracy: 0.4800\n",
            "Epoch 103/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.1333 - accuracy: 0.4400\n",
            "Epoch 104/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 2.1351 - accuracy: 0.4800\n",
            "Epoch 105/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 2.1634 - accuracy: 0.4100\n",
            "Epoch 106/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 2.1159 - accuracy: 0.4800\n",
            "Epoch 107/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.1086 - accuracy: 0.4400\n",
            "Epoch 108/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.0853 - accuracy: 0.4600\n",
            "Epoch 109/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 2.0783 - accuracy: 0.4700\n",
            "Epoch 110/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0754 - accuracy: 0.4400\n",
            "Epoch 111/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0478 - accuracy: 0.4800\n",
            "Epoch 112/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0379 - accuracy: 0.4800\n",
            "Epoch 113/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 2.0366 - accuracy: 0.4600\n",
            "Epoch 114/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 2.0424 - accuracy: 0.5100\n",
            "Epoch 115/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.1081 - accuracy: 0.4000\n",
            "Epoch 116/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 2.0247 - accuracy: 0.5000\n",
            "Epoch 117/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 2.0141 - accuracy: 0.4800\n",
            "Epoch 118/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 2.0037 - accuracy: 0.4700\n",
            "Epoch 119/200\n",
            "1/1 [==============================] - 0s 24ms/step - loss: 1.9888 - accuracy: 0.4800\n",
            "Epoch 120/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.9775 - accuracy: 0.5000\n",
            "Epoch 121/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.9717 - accuracy: 0.4800\n",
            "Epoch 122/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.9639 - accuracy: 0.5000\n",
            "Epoch 123/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.9649 - accuracy: 0.4800\n",
            "Epoch 124/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.9575 - accuracy: 0.5100\n",
            "Epoch 125/200\n",
            "1/1 [==============================] - 0s 43ms/step - loss: 1.9712 - accuracy: 0.4600\n",
            "Epoch 126/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9469 - accuracy: 0.5200\n",
            "Epoch 127/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.9588 - accuracy: 0.4300\n",
            "Epoch 128/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9071 - accuracy: 0.5100\n",
            "Epoch 129/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.8981 - accuracy: 0.5000\n",
            "Epoch 130/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.9001 - accuracy: 0.4900\n",
            "Epoch 131/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.8838 - accuracy: 0.5200\n",
            "Epoch 132/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.8827 - accuracy: 0.4900\n",
            "Epoch 133/200\n",
            "1/1 [==============================] - 0s 53ms/step - loss: 1.8695 - accuracy: 0.5100\n",
            "Epoch 134/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.8650 - accuracy: 0.5300\n",
            "Epoch 135/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.8700 - accuracy: 0.4800\n",
            "Epoch 136/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.8666 - accuracy: 0.5400\n",
            "Epoch 137/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.8982 - accuracy: 0.4300\n",
            "Epoch 138/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.8342 - accuracy: 0.5400\n",
            "Epoch 139/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.8240 - accuracy: 0.5200\n",
            "Epoch 140/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.8241 - accuracy: 0.5100\n",
            "Epoch 141/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.7952 - accuracy: 0.5400\n",
            "Epoch 142/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.7834 - accuracy: 0.5400\n",
            "Epoch 143/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.7758 - accuracy: 0.5500\n",
            "Epoch 144/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.7706 - accuracy: 0.5500\n",
            "Epoch 145/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.7657 - accuracy: 0.5500\n",
            "Epoch 146/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.7686 - accuracy: 0.5400\n",
            "Epoch 147/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.7542 - accuracy: 0.5500\n",
            "Epoch 148/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.7540 - accuracy: 0.5600\n",
            "Epoch 149/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.7820 - accuracy: 0.5200\n",
            "Epoch 150/200\n",
            "1/1 [==============================] - 0s 44ms/step - loss: 1.7471 - accuracy: 0.5700\n",
            "Epoch 151/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.7353 - accuracy: 0.5700\n",
            "Epoch 152/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.6991 - accuracy: 0.6000\n",
            "Epoch 153/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.6921 - accuracy: 0.6100\n",
            "Epoch 154/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.7033 - accuracy: 0.5400\n",
            "Epoch 155/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.6729 - accuracy: 0.6000\n",
            "Epoch 156/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.6630 - accuracy: 0.5900\n",
            "Epoch 157/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.6567 - accuracy: 0.6300\n",
            "Epoch 158/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.6564 - accuracy: 0.6000\n",
            "Epoch 159/200\n",
            "1/1 [==============================] - 0s 38ms/step - loss: 1.6472 - accuracy: 0.6400\n",
            "Epoch 160/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.6469 - accuracy: 0.5900\n",
            "Epoch 161/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.6386 - accuracy: 0.5900\n",
            "Epoch 162/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.6294 - accuracy: 0.6200\n",
            "Epoch 163/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.6281 - accuracy: 0.5900\n",
            "Epoch 164/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.6089 - accuracy: 0.6400\n",
            "Epoch 165/200\n",
            "1/1 [==============================] - 0s 25ms/step - loss: 1.6037 - accuracy: 0.6300\n",
            "Epoch 166/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.5732 - accuracy: 0.6600\n",
            "Epoch 167/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.5605 - accuracy: 0.6700\n",
            "Epoch 168/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.5532 - accuracy: 0.7000\n",
            "Epoch 169/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.5624 - accuracy: 0.6900\n",
            "Epoch 170/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.6267 - accuracy: 0.5900\n",
            "Epoch 171/200\n",
            "1/1 [==============================] - 0s 31ms/step - loss: 1.5524 - accuracy: 0.6500\n",
            "Epoch 172/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.5257 - accuracy: 0.7300\n",
            "Epoch 173/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.5119 - accuracy: 0.7000\n",
            "Epoch 174/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.5002 - accuracy: 0.7400\n",
            "Epoch 175/200\n",
            "1/1 [==============================] - 0s 40ms/step - loss: 1.4917 - accuracy: 0.7000\n",
            "Epoch 176/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.4839 - accuracy: 0.7400\n",
            "Epoch 177/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.4815 - accuracy: 0.7100\n",
            "Epoch 178/200\n",
            "1/1 [==============================] - 0s 29ms/step - loss: 1.4814 - accuracy: 0.7300\n",
            "Epoch 179/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.4903 - accuracy: 0.6600\n",
            "Epoch 180/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.4933 - accuracy: 0.7100\n",
            "Epoch 181/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.4776 - accuracy: 0.6700\n",
            "Epoch 182/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4470 - accuracy: 0.7700\n",
            "Epoch 183/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.4264 - accuracy: 0.7500\n",
            "Epoch 184/200\n",
            "1/1 [==============================] - 0s 33ms/step - loss: 1.4104 - accuracy: 0.7800\n",
            "Epoch 185/200\n",
            "1/1 [==============================] - 0s 36ms/step - loss: 1.3987 - accuracy: 0.7600\n",
            "Epoch 186/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3897 - accuracy: 0.7900\n",
            "Epoch 187/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.3808 - accuracy: 0.7600\n",
            "Epoch 188/200\n",
            "1/1 [==============================] - 0s 37ms/step - loss: 1.3779 - accuracy: 0.7900\n",
            "Epoch 189/200\n",
            "1/1 [==============================] - 0s 34ms/step - loss: 1.3701 - accuracy: 0.7800\n",
            "Epoch 190/200\n",
            "1/1 [==============================] - 0s 30ms/step - loss: 1.3756 - accuracy: 0.7900\n",
            "Epoch 191/200\n",
            "1/1 [==============================] - 0s 35ms/step - loss: 1.3687 - accuracy: 0.7600\n",
            "Epoch 192/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.3655 - accuracy: 0.7800\n",
            "Epoch 193/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.3593 - accuracy: 0.7800\n",
            "Epoch 194/200\n",
            "1/1 [==============================] - 0s 32ms/step - loss: 1.3391 - accuracy: 0.7900\n",
            "Epoch 195/200\n",
            "1/1 [==============================] - 0s 28ms/step - loss: 1.3221 - accuracy: 0.7800\n",
            "Epoch 196/200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.3061 - accuracy: 0.8000\n",
            "Epoch 197/200\n",
            "1/1 [==============================] - 0s 27ms/step - loss: 1.2925 - accuracy: 0.8000\n",
            "Epoch 198/200\n",
            "1/1 [==============================] - 0s 26ms/step - loss: 1.2845 - accuracy: 0.8100\n",
            "Epoch 199/200\n",
            "1/1 [==============================] - 0s 41ms/step - loss: 1.2720 - accuracy: 0.8300\n",
            "Epoch 200/200\n",
            "1/1 [==============================] - 0s 39ms/step - loss: 1.2672 - accuracy: 0.8100\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<tensorflow.python.keras.callbacks.History at 0x7fdcf005c3d0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6xQx1OUe9-bs"
      },
      "source": [
        "def prob_of_input_sentence(model, tokenizer, sentence):\r\n",
        "    print (\"Input Sentence:\", sentence)\r\n",
        "    encoded=tokenizer.texts_to_sequences([sentence])[0]\r\n",
        "    encoded.insert(0, 0)\r\n",
        "    encoded=np.array(encoded)\r\n",
        "    encoded=np.reshape(encoded, newshape=(1, -1))\r\n",
        "    prob = model.predict(encoded, verbose=0)\r\n",
        "    probability=1\r\n",
        "    for i in range (prob. shape[1]-1):\r\n",
        "        probability = probability * prob[0, i, encoded[0, i+1]]\r\n",
        "    print(\"Probability: \", probability)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "prxieX0pET2Z",
        "outputId": "146ffe1b-a388-478b-9bc1-7cd61b5fdf68"
      },
      "source": [
        "prob_of_input_sentence(model, tokenizer, \"It is well known that\")"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Sentence: It is well known that\n",
            "Probability:  1.1526633691371497e-06\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g6RARvylEaPD",
        "outputId": "1237cd55-a691-4505-b917-9d378b3578e2"
      },
      "source": [
        "prob_of_input_sentence(model, tokenizer, \"medical diagnosis takes more time than deciding\")"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Sentence: medical diagnosis takes more time than deciding\n",
            "Probability:  1.26546502015892e-18\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HbgIGFkFEtWx",
        "outputId": "73c1ef08-0aa5-42d0-9321-3d950779ec8e"
      },
      "source": [
        "prob_of_input_sentence(model, tokenizer, \"It is well known that medical diagnosis takes more time than deciding treatment for the condition\")"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Sentence: It is well known that medical diagnosis takes more time than deciding treatment for the condition\n",
            "Probability:  8.186663421780185e-22\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KI5gl2yE106",
        "outputId": "0275e8e3-26d6-4fa8-a6eb-267717847743"
      },
      "source": [
        "prob_of_input_sentence(model, tokenizer, \"It might require plenty of time\")"
      ],
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Input Sentence: It might require plenty of time\n",
            "Probability:  2.968899546582824e-10\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wCSRUyyg-cEl"
      },
      "source": [
        "#### Predicting Next Chars"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Au7QR_2pFHM1"
      },
      "source": [
        "shakespeare_url = \"https://raw.githubusercontent.com/karpathy/char-rnn/master/data/tinyshakespeare/input.txt\"\r\n",
        "filepath = keras.utils.get_file(\"shakespeare.txt\", shakespeare_url)\r\n",
        "with open(filepath) as f:\r\n",
        "    shakespeare_text = f.read()\r\n"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qPbl3HhH-hGP"
      },
      "source": [
        "tokenizer = keras.preprocessing.text.Tokenizer(char_level=True)\r\n",
        "tokenizer.fit_on_texts(shakespeare_text)"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Zr9zsAqS-i0i",
        "outputId": "20f8ba8d-98e6-41d1-d487-2f680e8c1f66"
      },
      "source": [
        "tokenizer.texts_to_sequences(['First'])"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[20, 6, 9, 8, 3]]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SV4CZYU6-j0D",
        "outputId": "be8e5dfb-1bf6-4b58-d668-343e5c172eae"
      },
      "source": [
        "tokenizer.sequences_to_texts([[20,6,9,8,3]])"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "['f i r s t']"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rjVxDG14-lMV",
        "outputId": "81a19768-7bcd-4bc1-ec4f-8aa34dc5c289"
      },
      "source": [
        "max_id = len(tokenizer.word_index)\r\n",
        "max_id"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "39"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6OjCem2m-oPZ"
      },
      "source": [
        "dataset_size = tokenizer.document_count"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DgvPuA5d-pbB",
        "outputId": "e6c58a05-d48f-40ca-dee6-0007a31f1d40"
      },
      "source": [
        "dataset_size"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1115394"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 25
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xfzRRQNs-quL"
      },
      "source": [
        "[encoded] = np.array(tokenizer.texts_to_sequences([shakespeare_text])) - 1"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LYueyveI-uym"
      },
      "source": [
        "train_size = dataset_size * 90 // 100\r\n",
        "dataset = tf.data.Dataset.from_tensor_slices(encoded[:train_size])"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wBhUtz_U-x5U"
      },
      "source": [
        "n_steps = 100\r\n",
        "window_length = n_steps + 1"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q-xY5DSF-zEY"
      },
      "source": [
        "dataset = dataset.window(window_length, shift=1, drop_remainder=True)"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NtCgyetw-0nS"
      },
      "source": [
        "dataset = dataset.flat_map(lambda window: window.batch(window_length))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7ceWB_aG-2Db"
      },
      "source": [
        "batch_size = 32\r\n",
        "dataset = dataset.shuffle(10000).batch(batch_size)\r\n",
        "dataset = dataset.map(lambda windows: (windows[:, :-1], windows[:, 1:]))"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u8qDJ6nC-3lW"
      },
      "source": [
        "dataset = dataset.map(\r\n",
        "    lambda X_batch, Y_batch: (tf.one_hot(X_batch, depth=max_id), Y_batch))"
      ],
      "execution_count": 32,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "o31fRp0C-4uF"
      },
      "source": [
        "dataset = dataset.prefetch(1)"
      ],
      "execution_count": 33,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RyUyaryq-8M-"
      },
      "source": [
        "import os\r\n",
        "\r\n",
        "checkpoint_dir = './training_checkpoints'\r\n",
        "checkpoint_prefix = os.path.join(checkpoint_dir, \"ckpt_{epoch}\")\r\n",
        "\r\n",
        "checkpoint_callback=tf.keras.callbacks.ModelCheckpoint(\r\n",
        "    filepath=checkpoint_prefix,\r\n",
        "    save_weights_only=True)"
      ],
      "execution_count": 34,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GI38mT88-9WU"
      },
      "source": [
        "class NvidiaUtilizationCallback(keras.callbacks.Callback):\r\n",
        "    def on_epoch_begin(self, epoch, logs):\r\n",
        "        text = !nvidia-smi\r\n",
        "        text = text[9][60:65] + ' GPU utilization'\r\n",
        "        print(text)"
      ],
      "execution_count": 35,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ADNT79-8-_hB",
        "outputId": "32353b1c-bd60-4e27-b0f3-9747f84e0084"
      },
      "source": [
        "model = keras.models.Sequential([\r\n",
        "    keras.layers.GRU(128, return_sequences=True, input_shape=[None, max_id]),\r\n",
        "    keras.layers.TimeDistributed(keras.layers.Dense(max_id, activation='softmax'))    \r\n",
        "])\r\n",
        "\r\n",
        "model.compile(loss = 'sparse_categorical_crossentropy', optimizer = 'adam')\r\n",
        "steps_per_epoch = train_size // batch_size // n_steps\r\n",
        "\r\n",
        "history = model.fit(dataset, epochs = 40, steps_per_epoch=steps_per_epoch, callbacks=[checkpoint_callback, NvidiaUtilizationCallback()])"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/40\n",
            "  0%  GPU utilization\n",
            "313/313 [==============================] - 12s 25ms/step - loss: 2.9229\n",
            "Epoch 2/40\n",
            " 35%  GPU utilization\n",
            "313/313 [==============================] - 8s 25ms/step - loss: 2.1208\n",
            "Epoch 3/40\n",
            " 57%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.8792\n",
            "Epoch 4/40\n",
            " 59%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.7314\n",
            "Epoch 5/40\n",
            " 39%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.5716\n",
            "Epoch 6/40\n",
            " 55%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.4022\n",
            "Epoch 7/40\n",
            " 60%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.3303\n",
            "Epoch 8/40\n",
            " 48%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2852\n",
            "Epoch 9/40\n",
            " 32%  GPU utilization\n",
            "313/313 [==============================] - 8s 25ms/step - loss: 1.2905\n",
            "Epoch 10/40\n",
            " 56%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2681\n",
            "Epoch 11/40\n",
            " 49%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2605\n",
            "Epoch 12/40\n",
            " 39%  GPU utilization\n",
            "313/313 [==============================] - 8s 25ms/step - loss: 1.2574\n",
            "Epoch 13/40\n",
            " 56%  GPU utilization\n",
            "313/313 [==============================] - 8s 25ms/step - loss: 1.2571\n",
            "Epoch 14/40\n",
            " 57%  GPU utilization\n",
            "313/313 [==============================] - 8s 25ms/step - loss: 1.3225\n",
            "Epoch 15/40\n",
            " 58%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.3153\n",
            "Epoch 16/40\n",
            " 56%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.3624\n",
            "Epoch 17/40\n",
            " 45%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2988\n",
            "Epoch 18/40\n",
            " 38%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2859\n",
            "Epoch 19/40\n",
            " 41%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2949\n",
            "Epoch 20/40\n",
            " 52%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2460\n",
            "Epoch 21/40\n",
            " 56%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2675\n",
            "Epoch 22/40\n",
            " 55%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2445\n",
            "Epoch 23/40\n",
            " 33%  GPU utilization\n",
            "313/313 [==============================] - 8s 23ms/step - loss: 1.2047\n",
            "Epoch 24/40\n",
            " 57%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2003\n",
            "Epoch 25/40\n",
            " 32%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2504\n",
            "Epoch 26/40\n",
            " 35%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2476\n",
            "Epoch 27/40\n",
            " 30%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2512\n",
            "Epoch 28/40\n",
            " 55%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2222\n",
            "Epoch 29/40\n",
            " 56%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.1491\n",
            "Epoch 30/40\n",
            " 37%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2171\n",
            "Epoch 31/40\n",
            " 47%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2373\n",
            "Epoch 32/40\n",
            " 54%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2801\n",
            "Epoch 33/40\n",
            " 56%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2598\n",
            "Epoch 34/40\n",
            " 55%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2563\n",
            "Epoch 35/40\n",
            " 42%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2774\n",
            "Epoch 36/40\n",
            " 58%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2773\n",
            "Epoch 37/40\n",
            " 58%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2430\n",
            "Epoch 38/40\n",
            " 35%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2608\n",
            "Epoch 39/40\n",
            " 47%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2483\n",
            "Epoch 40/40\n",
            " 56%  GPU utilization\n",
            "313/313 [==============================] - 8s 24ms/step - loss: 1.2629\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "AcTO-FB-_Cbh"
      },
      "source": [
        "def preprocess(texts):\r\n",
        "    X = np.array(tokenizer.texts_to_sequences(texts)) - 1\r\n",
        "    return tf.one_hot(X, max_id)"
      ],
      "execution_count": 37,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6DEtRDOC_DS2"
      },
      "source": [
        "X_new = preprocess([\"How are yo\"])"
      ],
      "execution_count": 38,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xE7-V5-5_Eqr"
      },
      "source": [
        "Y_pred = np.argmax(model.predict(X_new), axis=-1)"
      ],
      "execution_count": 39,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "kqO9YQsI_FiF",
        "outputId": "bec3d4e6-9144-4c9a-e063-89f4af9c5b9a"
      },
      "source": [
        "tokenizer.sequences_to_texts(Y_pred + 1)[0][-1]"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'u'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 40
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0sU0PErD_IIR"
      },
      "source": [
        "def next_char(text, temperature=1):\r\n",
        "    X_new = preprocess([text])\r\n",
        "    y_proba = model.predict(X_new)[0, -1:, :]\r\n",
        "    rescaled_logits = tf.math.log(y_proba) / temperature\r\n",
        "    char_id = tf.random.categorical(rescaled_logits, num_samples=1) + 1\r\n",
        "    return tokenizer.sequences_to_texts(char_id.numpy())[0]"
      ],
      "execution_count": 41,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DubT04ll_Ja-"
      },
      "source": [
        "def complete_text(text, n_chars=50, temperature=1):\r\n",
        "    for _ in range(n_chars):\r\n",
        "        text += next_char(text, temperature)\r\n",
        "    return text"
      ],
      "execution_count": 42,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "cPICPg8r_L2u",
        "outputId": "3e8f1675-cd30-49e8-f6af-5a1b4596314a"
      },
      "source": [
        "text_1 = complete_text(\"t\", temperature=0.2)\r\n",
        "text_1"
      ],
      "execution_count": 43,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"t the king surjoy:\\nlet's that he is a royal presenc\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "XaWi7fNnAwXw",
        "outputId": "df3a763c-2a99-4f99-adc7-0b6aece7ab4b"
      },
      "source": [
        "text_2 = complete_text(\"How are yo\", temperature=1)\r\n",
        "text_2"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"How are you so honore thou of thear strue, his head's londs.\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 44
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "FJrLEFdAA6VB",
        "outputId": "d751652d-be59-4633-dc10-18356943e2e3"
      },
      "source": [
        "text_3 = complete_text(\"How you doin\", temperature=1)\r\n",
        "text_3"
      ],
      "execution_count": 45,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "\"How you doinmy duey.\\n\\nking richard,\\nthat h'pray of not to-drea\""
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UaF6ukFsBKLb"
      },
      "source": [
        ""
      ],
      "execution_count": 45,
      "outputs": []
    }
  ]
}